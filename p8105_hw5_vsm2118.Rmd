---
title: "HW 5 Data Science"
author: "Victoria Mello (vsm2118)"
date: "November 13, 2023"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(rvest)
library(p8105.datasets)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


## Problem 1

For this problem, we are interested in data gathered and made public by _The Washington Post_ on homicides in 50 large U.S. cities. The code chunk below imports and cleans the data.

```{r}
homicide_df = 
  read_csv("data/homicide-data.csv", na = c("", "NA", "Unknown")) %>%
  mutate(
    city_state = str_c(city, state, sep = ", "),
    resolution = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved"
    )
  ) %>% 
  filter(city_state != "Tulsa, AL") 
```

The resulting dataframe has `r nrow(homicide_df)` entries, on variables that include the victim name, race, age, and sex; the date the homicide was reported; and the location of the homicide. In cleaning, I created a `city_state` variable that includes both city and state, and a `resolution` variable to indicate whether the case was closed by arrest. I also excluded one entry in Tulsa, AL, which is not a major US city and is most likely a data entry error. 

In the next code chunk, I group within cities and summarize to produce the total number of homicides and the number that are solved. 

```{r}
city_homicide_df = 
  homicide_df %>% 
  select(city_state, disposition, resolution) %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolution == "unsolved"))
```

Focusing only on Baltimore, MD, I can use the `prop.test` and `broom::tidy` functions to obtain an estimate and CI of the proportion of unsolved homicides in that city. The table below shows those values.

```{r}
bmore_test = 
  prop.test(
    x = filter(city_homicide_df, city_state == "Baltimore, MD") %>% pull(hom_unsolved),
    n = filter(city_homicide_df, city_state == "Baltimore, MD") %>% pull(hom_total)) 

broom::tidy(bmore_test) %>% 
  knitr::kable(digits = 3)
```

Building on this code, I can use functions in the `purrr` package to obtain estimates and CIs for the proportion of unsolved homicides in each city in my dataset. The code below implements this analysis. 

```{r}
test_results = 
  city_homicide_df %>% 
  mutate(
    prop_tests = map2(hom_unsolved, hom_total, \(x, y) prop.test(x = x, n = y)),
    tidy_tests = map(prop_tests, broom::tidy)) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high) %>% 
  mutate(city_state = fct_reorder(city_state, estimate))
```

Finally, I make a plot showing the estimate (and CI) of the proportion of unsolved homicides in each city.

```{r}
test_results %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

This figure suggests a very wide range in the rate at which homicides are solved -- Chicago is noticeably high and, given the narrowness of the CI, likely is the location of many homicides. 



## Problem 2

```{r message=FALSE}
 # Step 1: Get all file names
file_names <- list.files(path = "./data", pattern = ".csv", full.names = TRUE)

# Step 2: Use map to read in data for each subject
data_list <- map(file_names, ~read_csv(.x) %>%
                   mutate(subject_id = gsub("[^0-9]", "", .x),
                          arm = ifelse(grepl("con", .x), "control", "experimental")))

# Step 3: Tidy the data
tidy_data <- bind_rows(data_list) %>% 
  filter(!is.na(subject_id) & subject_id != "") %>%
  pivot_longer(cols = starts_with("week_"), names_to = "week", values_to = "observation") %>%
  mutate(week = as.numeric(str_remove(week, "week_")))

# Step 4: Create a spaghetti plot
study_plot <- ggplot(tidy_data, aes(x = week, y = observation, color = factor(subject_id), group = interaction(subject_id, arm))) +
  geom_line() +
  geom_point() +
  facet_wrap(~arm, scales = "free_y") + 
  labs(title = "Observation Values of Subjects in Control vs Experimental Study Arms Over 8 Weeks",
       x = "Week",
       y = "Observation Value",
       color = "Subject ID") +
  theme_minimal()

print(study_plot)
```

The control group consistently maintains observation values within the range of roughly -2.3 to 4.3 throughout all 8 weeks, encompassing all 10 subjects. Notably, the minimum observation occurs in week 6 for subject 5, while the maximum is recorded in week 5 for subject 10. The experimental arm exhibits a consistent positive/upward trajectory in observation values across all subjects throughout the 8-week duration. Subject 1 in the experimental arm records the lowest observation value in week 1, while the peak is observed in week 9 for subject 5. This suggests a positive correlation between observation values and time in the experimental arm, a trend not observed in the control arm.


## Problem 3

```{r}
# Function to simulate one-sample t-test and return estimate and p-value
sim_t_test <- function(true_mean = c(0, 1, 2, 3, 4, 5, 6), true_sd = 5, n_obs = 30, num_datasets = 5000) {
  results <- map_df(true_mean, function(mu) {
    dataframes <- replicate(num_datasets, rnorm(n_obs, mean = mu, sd = true_sd), simplify = FALSE)
  
    map_df(dataframes, function(dataset) {
      t_test_result <- t.test(dataset, mu = mu)
      tidy_result <- broom::tidy(t_test_result)
      data.frame(true_mean = mu, estimate_mean = tidy_result$estimate, p_value = tidy_result$p.value)
    })
  })
  return(results)
}

# Example usage
sim_results <- sim_t_test()
```


Plot 1: Power vs. True Value of μ
```{r}
power_plot_data <- sim_results %>%
  group_by(true_mean) %>%
  summarize(power = mean(p_value < 0.05))

ggplot(power_plot_data, aes(x = true_mean, y = power)) +
  geom_line() +
  geom_point() +  
  labs(title = "Power vs. True Value of μ",
       x = "True Value of μ",
       y = "Power")

```

There appears to be a non-linear relationship between effect size (true value of μ) and power. The fluctuations shown by the plot suggest varying sensitivity of the test to different effect sizes. Furthermore, the sharp changes at specific values of μ could be indicative of thresholds or critical points where the test's ability to detect the effect size changes. Whenever we execute the simulation with the generated data, the resulting graph exhibits variation, displaying a non-linear relationship on each iteration.



Plot 2: Average Estimate of μ̂ vs. True Value of μ
```{r}
estimate_plot_data <- sim_results %>%
  group_by(true_mean) %>%
  summarize(avg_estimate = mean(estimate_mean))

estimate_plot =
  estimate_plot_data %>% 
ggplot(aes(x = true_mean, y = avg_estimate)) +
  geom_line() +
  geom_point() + 
  labs(title = "Average Estimate of μ̂ vs. True Value of μ",
       x = "True Value of μ",
       y = "Average Estimate of μ̂")

print(estimate_plot)
```

A strong positive linear relationship exists between the actual mean values and the mean estimates derived from the simulation. This correlation is logical, as increasing the sample size leads to average estimated means closely resembling the true mean value.


Plot 3: Average Estimate of μ̂ in Rejected Samples vs. True Value of μ
```{r}
rejected_estimate_plot_data <- sim_results %>%
  filter(p_value <0.05) %>% 
  group_by(true_mean) %>%
  summarize(avg_estimate_rejected = mean(estimate_mean))

combined_data <- left_join(estimate_plot_data, rejected_estimate_plot_data, by = "true_mean")

ggplot(combined_data, aes(x = true_mean)) +
  geom_line(aes(y = avg_estimate, linetype = "All Samples"), color = "blue") +
  geom_point(aes(y = avg_estimate), color = "blue") +  
  geom_line(aes(y = avg_estimate_rejected, linetype = "Rejected Samples"), color = "red") +
  geom_point(aes(y = avg_estimate_rejected), shape = 5, size = 3, color = "red") +  
  labs(title = "Comparison of Average Estimate of μ̂",
       x = "True Value of μ",
       y = "Average Estimate of μ̂") +
  scale_linetype_manual(values = c("solid", "dashed"), labels = c("All Samples", "Rejected Samples")) +
  scale_color_manual(values = c("blue", "red")) +  
  theme_minimal() +  
  theme(legend.position = "top")  
```

The mean value of μ̂ across tests where the null hypothesis is rejected is approximatley equal to the true value of μ, with the average estimates of μ̂ more accurately approaching the true μ values as more samples are generated/run. The slight variations observed in the graph arise from the inherent random sampling variability present in the results.

